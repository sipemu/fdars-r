<!DOCTYPE html>
<!-- Generated by pkgdown: do not edit by hand --><html lang="en">
<head>
<meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
<meta charset="utf-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<title>Functional Regression â€¢ fdars</title>
<script src="../deps/jquery-3.6.0/jquery-3.6.0.min.js"></script><meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<link href="../deps/bootstrap-5.3.1/bootstrap.min.css" rel="stylesheet">
<script src="../deps/bootstrap-5.3.1/bootstrap.bundle.min.js"></script><link href="../deps/font-awesome-6.5.2/css/all.min.css" rel="stylesheet">
<link href="../deps/font-awesome-6.5.2/css/v4-shims.min.css" rel="stylesheet">
<script src="../deps/headroom-0.11.0/headroom.min.js"></script><script src="../deps/headroom-0.11.0/jQuery.headroom.min.js"></script><script src="../deps/bootstrap-toc-1.0.1/bootstrap-toc.min.js"></script><script src="../deps/clipboard.js-2.0.11/clipboard.min.js"></script><script src="../deps/search-1.0.0/autocomplete.jquery.min.js"></script><script src="../deps/search-1.0.0/fuse.min.js"></script><script src="../deps/search-1.0.0/mark.min.js"></script><!-- pkgdown --><script src="../pkgdown.js"></script><meta property="og:title" content="Functional Regression">
</head>
<body>
    <a href="#main" class="visually-hidden-focusable">Skip to contents</a>


    <nav class="navbar navbar-expand-lg fixed-top bg-light" data-bs-theme="light" aria-label="Site navigation"><div class="container">

    <a class="navbar-brand me-2" href="../index.html">fdars</a>

    <small class="nav-text text-muted me-auto" data-bs-toggle="tooltip" data-bs-placement="bottom" title="">0.3.0</small>


    <button class="navbar-toggler" type="button" data-bs-toggle="collapse" data-bs-target="#navbar" aria-controls="navbar" aria-expanded="false" aria-label="Toggle navigation">
      <span class="navbar-toggler-icon"></span>
    </button>

    <div id="navbar" class="collapse navbar-collapse ms-3">
      <ul class="navbar-nav me-auto">
<li class="nav-item"><a class="nav-link" href="../reference/index.html">Reference</a></li>
<li class="active nav-item dropdown">
  <button class="nav-link dropdown-toggle" type="button" id="dropdown-articles" data-bs-toggle="dropdown" aria-expanded="false" aria-haspopup="true">Articles</button>
  <ul class="dropdown-menu" aria-labelledby="dropdown-articles">
<li><h6 class="dropdown-header" data-toc-skip>Getting Started</h6></li>
    <li><a class="dropdown-item" href="../articles/introduction.html">Introduction to fdars</a></li>
    <li><a class="dropdown-item" href="../articles/custom-plotting.html">Custom Plotting with ggplot2</a></li>
    <li><a class="dropdown-item" href="../articles/intro-to-smoothing.html">Introduction to Smoothing</a></li>
    <li><a class="dropdown-item" href="../articles/working-with-derivatives.html">Working with Derivatives</a></li>
    <li><hr class="dropdown-divider"></li>
    <li><h6 class="dropdown-header" data-toc-skip>Core Methods</h6></li>
    <li><a class="dropdown-item" href="../articles/fpca.html">Functional PCA (FPCA)</a></li>
    <li><a class="dropdown-item" href="../articles/basis-representation.html">Basis Representation</a></li>
    <li><a class="dropdown-item" href="../articles/depth-functions.html">Depth Functions</a></li>
    <li><a class="dropdown-item" href="../articles/distance-metrics.html">Distance Metrics</a></li>
    <li><hr class="dropdown-divider"></li>
    <li><h6 class="dropdown-header" data-toc-skip>Analysis</h6></li>
    <li><a class="dropdown-item" href="../articles/clustering.html">Clustering</a></li>
    <li><a class="dropdown-item" href="../articles/outlier-detection.html">Outlier Detection</a></li>
    <li><a class="dropdown-item" href="../articles/regression.html">Regression</a></li>
    <li><a class="dropdown-item" href="../articles/seasonal-analysis.html">Seasonal Analysis</a></li>
    <li><hr class="dropdown-divider"></li>
    <li><h6 class="dropdown-header" data-toc-skip>Advanced</h6></li>
    <li><a class="dropdown-item" href="../articles/covariance-functions.html">Covariance Functions</a></li>
    <li><a class="dropdown-item" href="../articles/simulation-toolbox.html">Simulation Toolbox</a></li>
    <li><a class="dropdown-item" href="../articles/irregular-sampling.html">Irregular Sampling</a></li>
  </ul>
</li>
      </ul>
<ul class="navbar-nav">
<li class="nav-item"><form class="form-inline" role="search">
 <input class="form-control" type="search" name="search-input" id="search-input" autocomplete="off" aria-label="Search site" placeholder="Search for" data-search-index="../search.json">
</form></li>
<li class="nav-item"><a class="external-link nav-link" href="https://github.com/sipemu/fdars-r/" aria-label="GitHub"><span class="fa fab fa-github fa-lg"></span></a></li>
      </ul>
</div>


  </div>
</nav><div class="container template-article">




<div class="row">
  <main id="main" class="col-md-9"><div class="page-header">

      <h1>Functional Regression</h1>
            
      
      <small class="dont-index">Source: <a href="https://github.com/sipemu/fdars-r/blob/main/vignettes/regression.Rmd" class="external-link"><code>vignettes/regression.Rmd</code></a></small>
      <div class="d-none name"><code>regression.Rmd</code></div>
    </div>

    
    
<div class="section level2">
<h2 id="introduction">Introduction<a class="anchor" aria-label="anchor" href="#introduction"></a>
</h2>
<p>Functional regression extends classical regression to handle
functional predictors or responses. The most common setting is
<strong>scalar-on-function regression</strong>, where a scalar response
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>Y</mi><annotation encoding="application/x-tex">Y</annotation></semantics></math>
is predicted from a functional predictor
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>X</mi><mrow><mo stretchy="true" form="prefix">(</mo><mi>t</mi><mo stretchy="true" form="postfix">)</mo></mrow></mrow><annotation encoding="application/x-tex">X(t)</annotation></semantics></math>.</p>
<div class="section level3">
<h3 id="the-functional-linear-model">The Functional Linear Model<a class="anchor" aria-label="anchor" href="#the-functional-linear-model"></a>
</h3>
<p>The foundational model in functional regression is the
<strong>functional linear model</strong>:</p>
<p><math display="block" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>Y</mi><mi>i</mi></msub><mo>=</mo><mi>Î±</mi><mo>+</mo><msub><mo>âˆ«</mo><mi>ğ’¯</mi></msub><mi>Î²</mi><mrow><mo stretchy="true" form="prefix">(</mo><mi>t</mi><mo stretchy="true" form="postfix">)</mo></mrow><msub><mi>X</mi><mi>i</mi></msub><mrow><mo stretchy="true" form="prefix">(</mo><mi>t</mi><mo stretchy="true" form="postfix">)</mo></mrow><mspace width="0.167em"></mspace><mi>d</mi><mi>t</mi><mo>+</mo><msub><mi>Ïµ</mi><mi>i</mi></msub></mrow><annotation encoding="application/x-tex">Y_i = \alpha + \int_{\mathcal{T}} \beta(t) X_i(t) \, dt + \epsilon_i</annotation></semantics></math></p>
<p>where:</p>
<ul>
<li>
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><msub><mi>Y</mi><mi>i</mi></msub><annotation encoding="application/x-tex">Y_i</annotation></semantics></math>
is the scalar response for observation
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>i</mi><annotation encoding="application/x-tex">i</annotation></semantics></math>
</li>
<li>
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>X</mi><mi>i</mi></msub><mrow><mo stretchy="true" form="prefix">(</mo><mi>t</mi><mo stretchy="true" form="postfix">)</mo></mrow></mrow><annotation encoding="application/x-tex">X_i(t)</annotation></semantics></math>
is the functional predictor observed over domain
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>ğ’¯</mi><annotation encoding="application/x-tex">\mathcal{T}</annotation></semantics></math>
</li>
<li>
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>Î±</mi><annotation encoding="application/x-tex">\alpha</annotation></semantics></math>
is the intercept</li>
<li>
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>Î²</mi><mrow><mo stretchy="true" form="prefix">(</mo><mi>t</mi><mo stretchy="true" form="postfix">)</mo></mrow></mrow><annotation encoding="application/x-tex">\beta(t)</annotation></semantics></math>
is the <strong>coefficient function</strong> (unknown, to be
estimated)</li>
<li>
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>Ïµ</mi><mi>i</mi></msub><mo>âˆ¼</mo><mi>N</mi><mrow><mo stretchy="true" form="prefix">(</mo><mn>0</mn><mo>,</mo><msup><mi>Ïƒ</mi><mn>2</mn></msup><mo stretchy="true" form="postfix">)</mo></mrow></mrow><annotation encoding="application/x-tex">\epsilon_i \sim N(0, \sigma^2)</annotation></semantics></math>
are i.i.d. errors</li>
</ul>
<p>The integral
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mo>âˆ«</mo><mi>Î²</mi><mrow><mo stretchy="true" form="prefix">(</mo><mi>t</mi><mo stretchy="true" form="postfix">)</mo></mrow><msub><mi>X</mi><mi>i</mi></msub><mrow><mo stretchy="true" form="prefix">(</mo><mi>t</mi><mo stretchy="true" form="postfix">)</mo></mrow><mspace width="0.167em"></mspace><mi>d</mi><mi>t</mi></mrow><annotation encoding="application/x-tex">\int \beta(t) X_i(t) \, dt</annotation></semantics></math>
can be interpreted as a weighted average of the functional predictor,
where
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>Î²</mi><mrow><mo stretchy="true" form="prefix">(</mo><mi>t</mi><mo stretchy="true" form="postfix">)</mo></mrow></mrow><annotation encoding="application/x-tex">\beta(t)</annotation></semantics></math>
determines the importance of each time point
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>t</mi><annotation encoding="application/x-tex">t</annotation></semantics></math>
in predicting
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>Y</mi><annotation encoding="application/x-tex">Y</annotation></semantics></math>.</p>
</div>
<div class="section level3">
<h3 id="the-estimation-challenge">The Estimation Challenge<a class="anchor" aria-label="anchor" href="#the-estimation-challenge"></a>
</h3>
<p>Unlike classical regression where we estimate a finite number of
parameters, here we must estimate an entire <em>function</em>
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>Î²</mi><mrow><mo stretchy="true" form="prefix">(</mo><mi>t</mi><mo stretchy="true" form="postfix">)</mo></mrow></mrow><annotation encoding="application/x-tex">\beta(t)</annotation></semantics></math>.
This is an ill-posed inverse problem: infinitely many solutions may
exist, and small changes in the data can lead to large changes in the
estimate.</p>
<p><strong>fdars</strong> provides three main approaches to regularize
this problem:</p>
<ol style="list-style-type: decimal">
<li>
<strong>Principal Component Regression</strong>
(<code>fregre.pc</code>) â€” dimension reduction via FPCA</li>
<li>
<strong>Basis Expansion Regression</strong>
(<code>fregre.basis</code>) â€” represent
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>Î²</mi><mrow><mo stretchy="true" form="prefix">(</mo><mi>t</mi><mo stretchy="true" form="postfix">)</mo></mrow></mrow><annotation encoding="application/x-tex">\beta(t)</annotation></semantics></math>
in a finite basis</li>
<li>
<strong>Nonparametric Regression</strong> (<code>fregre.np</code>) â€”
make no parametric assumptions</li>
</ol>
<div class="sourceCode" id="cb1"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="kw"><a href="https://rdrr.io/r/base/library.html" class="external-link">library</a></span><span class="op">(</span><span class="va"><a href="https://sipemu.github.io/fdars-r/">fdars</a></span><span class="op">)</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; Attaching package: 'fdars'</span></span>
<span><span class="co">#&gt; The following objects are masked from 'package:stats':</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt;     cov, decompose, deriv, median, sd, var</span></span>
<span><span class="co">#&gt; The following object is masked from 'package:base':</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt;     norm</span></span>
<span><span class="kw"><a href="https://rdrr.io/r/base/library.html" class="external-link">library</a></span><span class="op">(</span><span class="va"><a href="https://ggplot2.tidyverse.org" class="external-link">ggplot2</a></span><span class="op">)</span></span>
<span><span class="fu"><a href="https://ggplot2.tidyverse.org/reference/get_theme.html" class="external-link">theme_set</a></span><span class="op">(</span><span class="fu"><a href="https://ggplot2.tidyverse.org/reference/ggtheme.html" class="external-link">theme_minimal</a></span><span class="op">(</span><span class="op">)</span><span class="op">)</span></span>
<span></span>
<span><span class="co"># Generate example data</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/base/Random.html" class="external-link">set.seed</a></span><span class="op">(</span><span class="fl">42</span><span class="op">)</span></span>
<span><span class="va">n</span> <span class="op">&lt;-</span> <span class="fl">100</span></span>
<span><span class="va">m</span> <span class="op">&lt;-</span> <span class="fl">50</span></span>
<span><span class="va">t_grid</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/seq.html" class="external-link">seq</a></span><span class="op">(</span><span class="fl">0</span>, <span class="fl">1</span>, length.out <span class="op">=</span> <span class="va">m</span><span class="op">)</span></span>
<span></span>
<span><span class="co"># Functional predictors</span></span>
<span><span class="va">X</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/matrix.html" class="external-link">matrix</a></span><span class="op">(</span><span class="fl">0</span>, <span class="va">n</span>, <span class="va">m</span><span class="op">)</span></span>
<span><span class="kw">for</span> <span class="op">(</span><span class="va">i</span> <span class="kw">in</span> <span class="fl">1</span><span class="op">:</span><span class="va">n</span><span class="op">)</span> <span class="op">{</span></span>
<span>  <span class="va">X</span><span class="op">[</span><span class="va">i</span>, <span class="op">]</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/Trig.html" class="external-link">sin</a></span><span class="op">(</span><span class="fl">2</span> <span class="op">*</span> <span class="va">pi</span> <span class="op">*</span> <span class="va">t_grid</span><span class="op">)</span> <span class="op">*</span> <span class="fu"><a href="https://rdrr.io/r/stats/Normal.html" class="external-link">rnorm</a></span><span class="op">(</span><span class="fl">1</span>, <span class="fl">1</span>, <span class="fl">0.3</span><span class="op">)</span> <span class="op">+</span></span>
<span>            <span class="fu"><a href="https://rdrr.io/r/base/Trig.html" class="external-link">cos</a></span><span class="op">(</span><span class="fl">4</span> <span class="op">*</span> <span class="va">pi</span> <span class="op">*</span> <span class="va">t_grid</span><span class="op">)</span> <span class="op">*</span> <span class="fu"><a href="https://rdrr.io/r/stats/Normal.html" class="external-link">rnorm</a></span><span class="op">(</span><span class="fl">1</span>, <span class="fl">0</span>, <span class="fl">0.2</span><span class="op">)</span> <span class="op">+</span></span>
<span>            <span class="fu"><a href="https://rdrr.io/r/stats/Normal.html" class="external-link">rnorm</a></span><span class="op">(</span><span class="va">m</span>, sd <span class="op">=</span> <span class="fl">0.1</span><span class="op">)</span></span>
<span><span class="op">}</span></span>
<span></span>
<span><span class="va">fd</span> <span class="op">&lt;-</span> <span class="fu"><a href="../reference/fdata.html">fdata</a></span><span class="op">(</span><span class="va">X</span>, argvals <span class="op">=</span> <span class="va">t_grid</span><span class="op">)</span></span>
<span></span>
<span><span class="co"># True coefficient function</span></span>
<span><span class="va">beta_true</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/Trig.html" class="external-link">sin</a></span><span class="op">(</span><span class="fl">2</span> <span class="op">*</span> <span class="va">pi</span> <span class="op">*</span> <span class="va">t_grid</span><span class="op">)</span></span>
<span></span>
<span><span class="co"># Generate response: Y = integral(beta * X) + noise</span></span>
<span><span class="va">y</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/numeric.html" class="external-link">numeric</a></span><span class="op">(</span><span class="va">n</span><span class="op">)</span></span>
<span><span class="kw">for</span> <span class="op">(</span><span class="va">i</span> <span class="kw">in</span> <span class="fl">1</span><span class="op">:</span><span class="va">n</span><span class="op">)</span> <span class="op">{</span></span>
<span>  <span class="va">y</span><span class="op">[</span><span class="va">i</span><span class="op">]</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/sum.html" class="external-link">sum</a></span><span class="op">(</span><span class="va">beta_true</span> <span class="op">*</span> <span class="va">X</span><span class="op">[</span><span class="va">i</span>, <span class="op">]</span><span class="op">)</span> <span class="op">/</span> <span class="va">m</span> <span class="op">+</span> <span class="fu"><a href="https://rdrr.io/r/stats/Normal.html" class="external-link">rnorm</a></span><span class="op">(</span><span class="fl">1</span>, sd <span class="op">=</span> <span class="fl">0.5</span><span class="op">)</span></span>
<span><span class="op">}</span></span>
<span></span>
<span><span class="fu"><a href="https://rdrr.io/r/graphics/plot.default.html" class="external-link">plot</a></span><span class="op">(</span><span class="va">fd</span><span class="op">)</span></span></code></pre></div>
<p><img src="regression_files/figure-html/setup-1.png" class="r-plt" alt="" width="100%"></p>
</div>
</div>
<div class="section level2">
<h2 id="principal-component-regression">Principal Component Regression<a class="anchor" aria-label="anchor" href="#principal-component-regression"></a>
</h2>
<p>Principal component regression (PCR) reduces the infinite-dimensional
problem to a finite-dimensional one by projecting the functional data
onto its principal components.</p>
<div class="section level3">
<h3 id="mathematical-formulation">Mathematical Formulation<a class="anchor" aria-label="anchor" href="#mathematical-formulation"></a>
</h3>
<p>Using functional principal component analysis (FPCA), each curve can
be represented as:</p>
<p><math display="block" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>X</mi><mi>i</mi></msub><mrow><mo stretchy="true" form="prefix">(</mo><mi>t</mi><mo stretchy="true" form="postfix">)</mo></mrow><mo>=</mo><mover><mi>X</mi><mo accent="true">â€¾</mo></mover><mrow><mo stretchy="true" form="prefix">(</mo><mi>t</mi><mo stretchy="true" form="postfix">)</mo></mrow><mo>+</mo><munderover><mo>âˆ‘</mo><mrow><mi>k</mi><mo>=</mo><mn>1</mn></mrow><mo accent="false">âˆ</mo></munderover><msub><mi>Î¾</mi><mrow><mi>i</mi><mi>k</mi></mrow></msub><msub><mi>Ï•</mi><mi>k</mi></msub><mrow><mo stretchy="true" form="prefix">(</mo><mi>t</mi><mo stretchy="true" form="postfix">)</mo></mrow></mrow><annotation encoding="application/x-tex">X_i(t) = \bar{X}(t) + \sum_{k=1}^{\infty} \xi_{ik} \phi_k(t)</annotation></semantics></math></p>
<p>where
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>Ï•</mi><mi>k</mi></msub><mrow><mo stretchy="true" form="prefix">(</mo><mi>t</mi><mo stretchy="true" form="postfix">)</mo></mrow></mrow><annotation encoding="application/x-tex">\phi_k(t)</annotation></semantics></math>
are the eigenfunctions (principal components) and
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>Î¾</mi><mrow><mi>i</mi><mi>k</mi></mrow></msub><mo>=</mo><mo>âˆ«</mo><mrow><mo stretchy="true" form="prefix">(</mo><msub><mi>X</mi><mi>i</mi></msub><mrow><mo stretchy="true" form="prefix">(</mo><mi>t</mi><mo stretchy="true" form="postfix">)</mo></mrow><mo>âˆ’</mo><mover><mi>X</mi><mo accent="true">â€¾</mo></mover><mrow><mo stretchy="true" form="prefix">(</mo><mi>t</mi><mo stretchy="true" form="postfix">)</mo></mrow><mo stretchy="true" form="postfix">)</mo></mrow><msub><mi>Ï•</mi><mi>k</mi></msub><mrow><mo stretchy="true" form="prefix">(</mo><mi>t</mi><mo stretchy="true" form="postfix">)</mo></mrow><mspace width="0.167em"></mspace><mi>d</mi><mi>t</mi></mrow><annotation encoding="application/x-tex">\xi_{ik} = \int (X_i(t) - \bar{X}(t)) \phi_k(t) \, dt</annotation></semantics></math>
are the <strong>PC scores</strong>.</p>
<p>Truncating at
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>K</mi><annotation encoding="application/x-tex">K</annotation></semantics></math>
components and substituting into the functional linear model gives:</p>
<p><math display="block" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>Y</mi><mi>i</mi></msub><mo>=</mo><mi>Î±</mi><mo>+</mo><munderover><mo>âˆ‘</mo><mrow><mi>k</mi><mo>=</mo><mn>1</mn></mrow><mi>K</mi></munderover><msub><mi>Î³</mi><mi>k</mi></msub><msub><mi>Î¾</mi><mrow><mi>i</mi><mi>k</mi></mrow></msub><mo>+</mo><msub><mi>Ïµ</mi><mi>i</mi></msub></mrow><annotation encoding="application/x-tex">Y_i = \alpha + \sum_{k=1}^{K} \gamma_k \xi_{ik} + \epsilon_i</annotation></semantics></math></p>
<p>where
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>Î³</mi><mi>k</mi></msub><mo>=</mo><mo>âˆ«</mo><mi>Î²</mi><mrow><mo stretchy="true" form="prefix">(</mo><mi>t</mi><mo stretchy="true" form="postfix">)</mo></mrow><msub><mi>Ï•</mi><mi>k</mi></msub><mrow><mo stretchy="true" form="prefix">(</mo><mi>t</mi><mo stretchy="true" form="postfix">)</mo></mrow><mspace width="0.167em"></mspace><mi>d</mi><mi>t</mi></mrow><annotation encoding="application/x-tex">\gamma_k = \int \beta(t) \phi_k(t) \, dt</annotation></semantics></math>.
This is now a standard multiple linear regression with predictors
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>Î¾</mi><mrow><mi>i</mi><mn>1</mn></mrow></msub><mo>,</mo><mi>â€¦</mi><mo>,</mo><msub><mi>Î¾</mi><mrow><mi>i</mi><mi>K</mi></mrow></msub></mrow><annotation encoding="application/x-tex">\xi_{i1}, \ldots, \xi_{iK}</annotation></semantics></math>.</p>
<p>The coefficient function is reconstructed as:</p>
<p><math display="block" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mover><mi>Î²</mi><mo accent="true">Ì‚</mo></mover><mrow><mo stretchy="true" form="prefix">(</mo><mi>t</mi><mo stretchy="true" form="postfix">)</mo></mrow><mo>=</mo><munderover><mo>âˆ‘</mo><mrow><mi>k</mi><mo>=</mo><mn>1</mn></mrow><mi>K</mi></munderover><msub><mover><mi>Î³</mi><mo accent="true">Ì‚</mo></mover><mi>k</mi></msub><msub><mi>Ï•</mi><mi>k</mi></msub><mrow><mo stretchy="true" form="prefix">(</mo><mi>t</mi><mo stretchy="true" form="postfix">)</mo></mrow></mrow><annotation encoding="application/x-tex">\hat{\beta}(t) = \sum_{k=1}^{K} \hat{\gamma}_k \phi_k(t)</annotation></semantics></math></p>
</div>
<div class="section level3">
<h3 id="choosing-the-number-of-components">Choosing the Number of Components<a class="anchor" aria-label="anchor" href="#choosing-the-number-of-components"></a>
</h3>
<p>The key tuning parameter is
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>K</mi><annotation encoding="application/x-tex">K</annotation></semantics></math>,
the number of principal components:</p>
<ul>
<li>
<strong>Too few</strong>: underfitting, missing important variation
in
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>X</mi><mrow><mo stretchy="true" form="prefix">(</mo><mi>t</mi><mo stretchy="true" form="postfix">)</mo></mrow></mrow><annotation encoding="application/x-tex">X(t)</annotation></semantics></math>
</li>
<li>
<strong>Too many</strong>: overfitting, including noise
components</li>
</ul>
<p>Cross-validation or information criteria (AIC, BIC) can guide the
choice.</p>
</div>
<div class="section level3">
<h3 id="basic-usage">Basic Usage<a class="anchor" aria-label="anchor" href="#basic-usage"></a>
</h3>
<div class="sourceCode" id="cb2"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="co"># Fit PC regression with 3 components</span></span>
<span><span class="va">fit_pc</span> <span class="op">&lt;-</span> <span class="fu"><a href="../reference/fregre.pc.html">fregre.pc</a></span><span class="op">(</span><span class="va">fd</span>, <span class="va">y</span>, ncomp <span class="op">=</span> <span class="fl">3</span><span class="op">)</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/base/print.html" class="external-link">print</a></span><span class="op">(</span><span class="va">fit_pc</span><span class="op">)</span></span>
<span><span class="co">#&gt; Functional regression model</span></span>
<span><span class="co">#&gt;   Number of observations: 100 </span></span>
<span><span class="co">#&gt;   R-squared: 0.1682634</span></span></code></pre></div>
</div>
<div class="section level3">
<h3 id="examining-the-fit">Examining the Fit<a class="anchor" aria-label="anchor" href="#examining-the-fit"></a>
</h3>
<div class="sourceCode" id="cb3"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="co"># Fitted values</span></span>
<span><span class="va">fitted_pc</span> <span class="op">&lt;-</span> <span class="va">fit_pc</span><span class="op">$</span><span class="va">fitted.values</span></span>
<span></span>
<span><span class="co"># Residuals</span></span>
<span><span class="va">residuals_pc</span> <span class="op">&lt;-</span> <span class="va">y</span> <span class="op">-</span> <span class="va">fitted_pc</span></span>
<span></span>
<span><span class="co"># R-squared</span></span>
<span><span class="va">r2_pc</span> <span class="op">&lt;-</span> <span class="fl">1</span> <span class="op">-</span> <span class="fu"><a href="https://rdrr.io/r/base/sum.html" class="external-link">sum</a></span><span class="op">(</span><span class="va">residuals_pc</span><span class="op">^</span><span class="fl">2</span><span class="op">)</span> <span class="op">/</span> <span class="fu"><a href="https://rdrr.io/r/base/sum.html" class="external-link">sum</a></span><span class="op">(</span><span class="op">(</span><span class="va">y</span> <span class="op">-</span> <span class="fu"><a href="https://rdrr.io/r/base/mean.html" class="external-link">mean</a></span><span class="op">(</span><span class="va">y</span><span class="op">)</span><span class="op">)</span><span class="op">^</span><span class="fl">2</span><span class="op">)</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/base/cat.html" class="external-link">cat</a></span><span class="op">(</span><span class="st">"R-squared:"</span>, <span class="fu"><a href="https://rdrr.io/r/base/Round.html" class="external-link">round</a></span><span class="op">(</span><span class="va">r2_pc</span>, <span class="fl">3</span><span class="op">)</span>, <span class="st">"\n"</span><span class="op">)</span></span>
<span><span class="co">#&gt; R-squared: 0.168</span></span></code></pre></div>
</div>
<div class="section level3">
<h3 id="cross-validation-for-component-selection">Cross-Validation for Component Selection<a class="anchor" aria-label="anchor" href="#cross-validation-for-component-selection"></a>
</h3>
<div class="sourceCode" id="cb4"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="co"># Find optimal number of components</span></span>
<span><span class="va">cv_pc</span> <span class="op">&lt;-</span> <span class="fu"><a href="../reference/fregre.pc.cv.html">fregre.pc.cv</a></span><span class="op">(</span><span class="va">fd</span>, <span class="va">y</span>, kmax <span class="op">=</span> <span class="fl">10</span><span class="op">)</span></span>
<span></span>
<span><span class="fu"><a href="https://rdrr.io/r/base/cat.html" class="external-link">cat</a></span><span class="op">(</span><span class="st">"Optimal number of components:"</span>, <span class="va">cv_pc</span><span class="op">$</span><span class="va">ncomp.opt</span>, <span class="st">"\n"</span><span class="op">)</span></span>
<span><span class="co">#&gt; Optimal number of components:</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/base/cat.html" class="external-link">cat</a></span><span class="op">(</span><span class="st">"CV error by component:\n"</span><span class="op">)</span></span>
<span><span class="co">#&gt; CV error by component:</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/base/print.html" class="external-link">print</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/Round.html" class="external-link">round</a></span><span class="op">(</span><span class="va">cv_pc</span><span class="op">$</span><span class="va">cv.error</span>, <span class="fl">4</span><span class="op">)</span><span class="op">)</span></span>
<span><span class="co">#&gt;      1      2      3      4      5      6      7      8      9     10     11 </span></span>
<span><span class="co">#&gt; 0.2674 0.2700 0.2720 0.2735 0.2785 0.2735 0.2691 0.2718 0.2728 0.2744 0.2735 </span></span>
<span><span class="co">#&gt;     12     13     14     15 </span></span>
<span><span class="co">#&gt; 0.2746 0.2714 0.2703 0.2746</span></span></code></pre></div>
</div>
<div class="section level3">
<h3 id="prediction">Prediction<a class="anchor" aria-label="anchor" href="#prediction"></a>
</h3>
<div class="sourceCode" id="cb5"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="co"># Split data</span></span>
<span><span class="va">train_idx</span> <span class="op">&lt;-</span> <span class="fl">1</span><span class="op">:</span><span class="fl">80</span></span>
<span><span class="va">test_idx</span> <span class="op">&lt;-</span> <span class="fl">81</span><span class="op">:</span><span class="fl">100</span></span>
<span></span>
<span><span class="va">fd_train</span> <span class="op">&lt;-</span> <span class="va">fd</span><span class="op">[</span><span class="va">train_idx</span>, <span class="op">]</span></span>
<span><span class="va">fd_test</span> <span class="op">&lt;-</span> <span class="va">fd</span><span class="op">[</span><span class="va">test_idx</span>, <span class="op">]</span></span>
<span><span class="va">y_train</span> <span class="op">&lt;-</span> <span class="va">y</span><span class="op">[</span><span class="va">train_idx</span><span class="op">]</span></span>
<span><span class="va">y_test</span> <span class="op">&lt;-</span> <span class="va">y</span><span class="op">[</span><span class="va">test_idx</span><span class="op">]</span></span>
<span></span>
<span><span class="co"># Fit on training data</span></span>
<span><span class="va">fit_train</span> <span class="op">&lt;-</span> <span class="fu"><a href="../reference/fregre.pc.html">fregre.pc</a></span><span class="op">(</span><span class="va">fd_train</span>, <span class="va">y_train</span>, ncomp <span class="op">=</span> <span class="fl">3</span><span class="op">)</span></span>
<span></span>
<span><span class="co"># Predict on test data</span></span>
<span><span class="va">y_pred</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/stats/predict.html" class="external-link">predict</a></span><span class="op">(</span><span class="va">fit_train</span>, <span class="va">fd_test</span><span class="op">)</span></span>
<span></span>
<span><span class="co"># Evaluate</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/base/cat.html" class="external-link">cat</a></span><span class="op">(</span><span class="st">"Test RMSE:"</span>, <span class="fu"><a href="https://rdrr.io/r/base/Round.html" class="external-link">round</a></span><span class="op">(</span><span class="fu"><a href="../reference/pred.RMSE.html">pred.RMSE</a></span><span class="op">(</span><span class="va">y_test</span>, <span class="va">y_pred</span><span class="op">)</span>, <span class="fl">3</span><span class="op">)</span>, <span class="st">"\n"</span><span class="op">)</span></span>
<span><span class="co">#&gt; Test RMSE: 0.457</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/base/cat.html" class="external-link">cat</a></span><span class="op">(</span><span class="st">"Test R2:"</span>, <span class="fu"><a href="https://rdrr.io/r/base/Round.html" class="external-link">round</a></span><span class="op">(</span><span class="fu"><a href="../reference/pred.R2.html">pred.R2</a></span><span class="op">(</span><span class="va">y_test</span>, <span class="va">y_pred</span><span class="op">)</span>, <span class="fl">3</span><span class="op">)</span>, <span class="st">"\n"</span><span class="op">)</span></span>
<span><span class="co">#&gt; Test R2: 0.219</span></span></code></pre></div>
</div>
</div>
<div class="section level2">
<h2 id="basis-expansion-regression">Basis Expansion Regression<a class="anchor" aria-label="anchor" href="#basis-expansion-regression"></a>
</h2>
<p>Basis expansion regression represents both the functional predictor
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>X</mi><mrow><mo stretchy="true" form="prefix">(</mo><mi>t</mi><mo stretchy="true" form="postfix">)</mo></mrow></mrow><annotation encoding="application/x-tex">X(t)</annotation></semantics></math>
and the coefficient function
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>Î²</mi><mrow><mo stretchy="true" form="prefix">(</mo><mi>t</mi><mo stretchy="true" form="postfix">)</mo></mrow></mrow><annotation encoding="application/x-tex">\beta(t)</annotation></semantics></math>
using a finite set of basis functions, reducing the infinite-dimensional
problem to a finite-dimensional one.</p>
<div class="section level3">
<h3 id="mathematical-formulation-1">Mathematical Formulation<a class="anchor" aria-label="anchor" href="#mathematical-formulation-1"></a>
</h3>
<p>Let
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mo stretchy="false" form="prefix">{</mo><msub><mi>B</mi><mi>j</mi></msub><mrow><mo stretchy="true" form="prefix">(</mo><mi>t</mi><mo stretchy="true" form="postfix">)</mo></mrow><msubsup><mo stretchy="false" form="postfix">}</mo><mrow><mi>j</mi><mo>=</mo><mn>1</mn></mrow><mi>J</mi></msubsup></mrow><annotation encoding="application/x-tex">\{B_j(t)\}_{j=1}^{J}</annotation></semantics></math>
be a set of basis functions (e.g., B-splines or Fourier). We expand:</p>
<p><math display="block" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>X</mi><mi>i</mi></msub><mrow><mo stretchy="true" form="prefix">(</mo><mi>t</mi><mo stretchy="true" form="postfix">)</mo></mrow><mo>=</mo><munderover><mo>âˆ‘</mo><mrow><mi>j</mi><mo>=</mo><mn>1</mn></mrow><mi>J</mi></munderover><msub><mi>c</mi><mrow><mi>i</mi><mi>j</mi></mrow></msub><msub><mi>B</mi><mi>j</mi></msub><mrow><mo stretchy="true" form="prefix">(</mo><mi>t</mi><mo stretchy="true" form="postfix">)</mo></mrow><mspace width="1.0em"></mspace><mtext mathvariant="normal">and</mtext><mspace width="1.0em"></mspace><mi>Î²</mi><mrow><mo stretchy="true" form="prefix">(</mo><mi>t</mi><mo stretchy="true" form="postfix">)</mo></mrow><mo>=</mo><munderover><mo>âˆ‘</mo><mrow><mi>j</mi><mo>=</mo><mn>1</mn></mrow><mi>J</mi></munderover><msub><mi>b</mi><mi>j</mi></msub><msub><mi>B</mi><mi>j</mi></msub><mrow><mo stretchy="true" form="prefix">(</mo><mi>t</mi><mo stretchy="true" form="postfix">)</mo></mrow></mrow><annotation encoding="application/x-tex">X_i(t) = \sum_{j=1}^{J} c_{ij} B_j(t) \quad \text{and} \quad \beta(t) = \sum_{j=1}^{J} b_j B_j(t)</annotation></semantics></math></p>
<p>Substituting into the functional linear model:</p>
<p><math display="block" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>Y</mi><mi>i</mi></msub><mo>=</mo><mi>Î±</mi><mo>+</mo><mo>âˆ«</mo><mrow><mo stretchy="true" form="prefix">(</mo><munderover><mo>âˆ‘</mo><mrow><mi>j</mi><mo>=</mo><mn>1</mn></mrow><mi>J</mi></munderover><msub><mi>b</mi><mi>j</mi></msub><msub><mi>B</mi><mi>j</mi></msub><mrow><mo stretchy="true" form="prefix">(</mo><mi>t</mi><mo stretchy="true" form="postfix">)</mo></mrow><mo stretchy="true" form="postfix">)</mo></mrow><mrow><mo stretchy="true" form="prefix">(</mo><munderover><mo>âˆ‘</mo><mrow><mi>k</mi><mo>=</mo><mn>1</mn></mrow><mi>J</mi></munderover><msub><mi>c</mi><mrow><mi>i</mi><mi>k</mi></mrow></msub><msub><mi>B</mi><mi>k</mi></msub><mrow><mo stretchy="true" form="prefix">(</mo><mi>t</mi><mo stretchy="true" form="postfix">)</mo></mrow><mo stretchy="true" form="postfix">)</mo></mrow><mi>d</mi><mi>t</mi><mo>+</mo><msub><mi>Ïµ</mi><mi>i</mi></msub></mrow><annotation encoding="application/x-tex">Y_i = \alpha + \int \left(\sum_{j=1}^{J} b_j B_j(t)\right) \left(\sum_{k=1}^{J} c_{ik} B_k(t)\right) dt + \epsilon_i</annotation></semantics></math></p>
<p>This simplifies to:</p>
<p><math display="block" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>Y</mi><mi>i</mi></msub><mo>=</mo><mi>Î±</mi><mo>+</mo><msubsup><mi>ğœ</mi><mi>i</mi><mi>âŠ¤</mi></msubsup><mi>ğ–</mi><mi>ğ›</mi><mo>+</mo><msub><mi>Ïµ</mi><mi>i</mi></msub></mrow><annotation encoding="application/x-tex">Y_i = \alpha + \mathbf{c}_i^\top \mathbf{W} \mathbf{b} + \epsilon_i</annotation></semantics></math></p>
<p>where
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>ğœ</mi><mi>i</mi></msub><mo>=</mo><msup><mrow><mo stretchy="true" form="prefix">(</mo><msub><mi>c</mi><mrow><mi>i</mi><mn>1</mn></mrow></msub><mo>,</mo><mi>â€¦</mi><mo>,</mo><msub><mi>c</mi><mrow><mi>i</mi><mi>J</mi></mrow></msub><mo stretchy="true" form="postfix">)</mo></mrow><mi>âŠ¤</mi></msup></mrow><annotation encoding="application/x-tex">\mathbf{c}_i = (c_{i1}, \ldots, c_{iJ})^\top</annotation></semantics></math>
are the basis coefficients of
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>X</mi><mi>i</mi></msub><mrow><mo stretchy="true" form="prefix">(</mo><mi>t</mi><mo stretchy="true" form="postfix">)</mo></mrow></mrow><annotation encoding="application/x-tex">X_i(t)</annotation></semantics></math>,
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>ğ›</mi><mo>=</mo><msup><mrow><mo stretchy="true" form="prefix">(</mo><msub><mi>b</mi><mn>1</mn></msub><mo>,</mo><mi>â€¦</mi><mo>,</mo><msub><mi>b</mi><mi>J</mi></msub><mo stretchy="true" form="postfix">)</mo></mrow><mi>âŠ¤</mi></msup></mrow><annotation encoding="application/x-tex">\mathbf{b} = (b_1, \ldots, b_J)^\top</annotation></semantics></math>
are the unknown coefficients of
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>Î²</mi><mrow><mo stretchy="true" form="prefix">(</mo><mi>t</mi><mo stretchy="true" form="postfix">)</mo></mrow></mrow><annotation encoding="application/x-tex">\beta(t)</annotation></semantics></math>,
and
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>ğ–</mi><annotation encoding="application/x-tex">\mathbf{W}</annotation></semantics></math>
is the <strong>inner product matrix</strong> with entries
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>W</mi><mrow><mi>j</mi><mi>k</mi></mrow></msub><mo>=</mo><mo>âˆ«</mo><msub><mi>B</mi><mi>j</mi></msub><mrow><mo stretchy="true" form="prefix">(</mo><mi>t</mi><mo stretchy="true" form="postfix">)</mo></mrow><msub><mi>B</mi><mi>k</mi></msub><mrow><mo stretchy="true" form="prefix">(</mo><mi>t</mi><mo stretchy="true" form="postfix">)</mo></mrow><mspace width="0.167em"></mspace><mi>d</mi><mi>t</mi></mrow><annotation encoding="application/x-tex">W_{jk} = \int B_j(t) B_k(t) \, dt</annotation></semantics></math>.</p>
</div>
<div class="section level3">
<h3 id="ridge-regularization">Ridge Regularization<a class="anchor" aria-label="anchor" href="#ridge-regularization"></a>
</h3>
<p>To prevent overfitting (especially with many basis functions), we add
a roughness penalty. The <strong>penalized least squares</strong>
objective is:</p>
<p><math display="block" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><munder><mo>min</mo><mrow><mi>Î±</mi><mo>,</mo><mi>ğ›</mi></mrow></munder><munderover><mo>âˆ‘</mo><mrow><mi>i</mi><mo>=</mo><mn>1</mn></mrow><mi>n</mi></munderover><msup><mrow><mo stretchy="true" form="prefix">(</mo><msub><mi>Y</mi><mi>i</mi></msub><mo>âˆ’</mo><mi>Î±</mi><mo>âˆ’</mo><msubsup><mi>ğœ</mi><mi>i</mi><mi>âŠ¤</mi></msubsup><mi>ğ–</mi><mi>ğ›</mi><mo stretchy="true" form="postfix">)</mo></mrow><mn>2</mn></msup><mo>+</mo><mi>Î»</mi><mo>âˆ«</mo><msup><mrow><mo stretchy="true" form="prefix">[</mo><mi>Î²</mi><mi>â€³</mi><mrow><mo stretchy="true" form="prefix">(</mo><mi>t</mi><mo stretchy="true" form="postfix">)</mo></mrow><mo stretchy="true" form="postfix">]</mo></mrow><mn>2</mn></msup><mi>d</mi><mi>t</mi></mrow><annotation encoding="application/x-tex">\min_{\alpha, \mathbf{b}} \sum_{i=1}^{n} \left(Y_i - \alpha - \mathbf{c}_i^\top \mathbf{W} \mathbf{b}\right)^2 + \lambda \int \left[\beta''(t)\right]^2 dt</annotation></semantics></math></p>
<p>The penalty
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mo>âˆ«</mo><msup><mrow><mo stretchy="true" form="prefix">[</mo><mi>Î²</mi><mi>â€³</mi><mrow><mo stretchy="true" form="prefix">(</mo><mi>t</mi><mo stretchy="true" form="postfix">)</mo></mrow><mo stretchy="true" form="postfix">]</mo></mrow><mn>2</mn></msup><mi>d</mi><mi>t</mi></mrow><annotation encoding="application/x-tex">\int [\beta''(t)]^2 dt</annotation></semantics></math>
discourages rapid oscillations. In matrix form:</p>
<p><math display="block" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><munder><mo>min</mo><mrow><mi>Î±</mi><mo>,</mo><mi>ğ›</mi></mrow></munder><mo stretchy="false" form="postfix">âˆ¥</mo><mi>ğ˜</mi><mo>âˆ’</mo><mi>Î±</mi><mn>ğŸ</mn><mo>âˆ’</mo><mi>ğ‚</mi><mi>ğ–</mi><mi>ğ›</mi><msup><mo stretchy="false" form="postfix">âˆ¥</mo><mn>2</mn></msup><mo>+</mo><mi>Î»</mi><msup><mi>ğ›</mi><mi>âŠ¤</mi></msup><mi>ğ‘</mi><mi>ğ›</mi></mrow><annotation encoding="application/x-tex">\min_{\alpha, \mathbf{b}} \|\mathbf{Y} - \alpha \mathbf{1} - \mathbf{C}\mathbf{W}\mathbf{b}\|^2 + \lambda \mathbf{b}^\top \mathbf{R} \mathbf{b}</annotation></semantics></math></p>
<p>where
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>ğ‘</mi><annotation encoding="application/x-tex">\mathbf{R}</annotation></semantics></math>
is the roughness penalty matrix with
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>R</mi><mrow><mi>j</mi><mi>k</mi></mrow></msub><mo>=</mo><mo>âˆ«</mo><msub><mi>B</mi><mi>j</mi></msub><mi>â€³</mi><mrow><mo stretchy="true" form="prefix">(</mo><mi>t</mi><mo stretchy="true" form="postfix">)</mo></mrow><msub><mi>B</mi><mi>k</mi></msub><mi>â€³</mi><mrow><mo stretchy="true" form="prefix">(</mo><mi>t</mi><mo stretchy="true" form="postfix">)</mo></mrow><mspace width="0.167em"></mspace><mi>d</mi><mi>t</mi></mrow><annotation encoding="application/x-tex">R_{jk} = \int B_j''(t) B_k''(t) \, dt</annotation></semantics></math>.</p>
<p>The solution is:</p>
<p><math display="block" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mover><mi>ğ›</mi><mo accent="true">Ì‚</mo></mover><mo>=</mo><msup><mrow><mo stretchy="true" form="prefix">(</mo><msup><mi>ğ–</mi><mi>âŠ¤</mi></msup><msup><mi>ğ‚</mi><mi>âŠ¤</mi></msup><mi>ğ‚</mi><mi>ğ–</mi><mo>+</mo><mi>Î»</mi><mi>ğ‘</mi><mo stretchy="true" form="postfix">)</mo></mrow><mrow><mo>âˆ’</mo><mn>1</mn></mrow></msup><msup><mi>ğ–</mi><mi>âŠ¤</mi></msup><msup><mi>ğ‚</mi><mi>âŠ¤</mi></msup><mrow><mo stretchy="true" form="prefix">(</mo><mi>ğ˜</mi><mo>âˆ’</mo><mover><mi>Y</mi><mo accent="true">â€¾</mo></mover><mo stretchy="true" form="postfix">)</mo></mrow></mrow><annotation encoding="application/x-tex">\hat{\mathbf{b}} = \left(\mathbf{W}^\top \mathbf{C}^\top \mathbf{C} \mathbf{W} + \lambda \mathbf{R}\right)^{-1} \mathbf{W}^\top \mathbf{C}^\top (\mathbf{Y} - \bar{Y})</annotation></semantics></math></p>
</div>
<div class="section level3">
<h3 id="basis-choice">Basis Choice<a class="anchor" aria-label="anchor" href="#basis-choice"></a>
</h3>
<ul>
<li>
<strong>B-splines</strong>: Flexible, local support, good for
non-periodic data</li>
<li>
<strong>Fourier</strong>: Natural for periodic data, global
support</li>
</ul>
</div>
<div class="section level3">
<h3 id="basic-usage-1">Basic Usage<a class="anchor" aria-label="anchor" href="#basic-usage-1"></a>
</h3>
<div class="sourceCode" id="cb6"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="co"># Fit basis regression with 15 B-spline basis functions</span></span>
<span><span class="va">fit_basis</span> <span class="op">&lt;-</span> <span class="fu"><a href="../reference/fregre.basis.html">fregre.basis</a></span><span class="op">(</span><span class="va">fd</span>, <span class="va">y</span>, nbasis <span class="op">=</span> <span class="fl">15</span>, type <span class="op">=</span> <span class="st">"bspline"</span><span class="op">)</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/base/print.html" class="external-link">print</a></span><span class="op">(</span><span class="va">fit_basis</span><span class="op">)</span></span>
<span><span class="co">#&gt; Functional regression model</span></span>
<span><span class="co">#&gt;   Number of observations: 100 </span></span>
<span><span class="co">#&gt;   R-squared: 0.5805754</span></span></code></pre></div>
</div>
<div class="section level3">
<h3 id="regularization">Regularization<a class="anchor" aria-label="anchor" href="#regularization"></a>
</h3>
<p>The <code>lambda</code> parameter controls regularization:</p>
<div class="sourceCode" id="cb7"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="co"># Higher lambda = more regularization</span></span>
<span><span class="va">fit_basis_reg</span> <span class="op">&lt;-</span> <span class="fu"><a href="../reference/fregre.basis.html">fregre.basis</a></span><span class="op">(</span><span class="va">fd</span>, <span class="va">y</span>, nbasis <span class="op">=</span> <span class="fl">15</span>, type <span class="op">=</span> <span class="st">"bspline"</span>, lambda <span class="op">=</span> <span class="fl">1</span><span class="op">)</span></span></code></pre></div>
</div>
<div class="section level3">
<h3 id="cross-validation-for-lambda">Cross-Validation for Lambda<a class="anchor" aria-label="anchor" href="#cross-validation-for-lambda"></a>
</h3>
<div class="sourceCode" id="cb8"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="co"># Find optimal lambda</span></span>
<span><span class="va">cv_basis</span> <span class="op">&lt;-</span> <span class="fu"><a href="../reference/fregre.basis.cv.html">fregre.basis.cv</a></span><span class="op">(</span><span class="va">fd</span>, <span class="va">y</span>, nbasis <span class="op">=</span> <span class="fl">15</span>, type <span class="op">=</span> <span class="st">"bspline"</span>,</span>
<span>                            lambda <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html" class="external-link">c</a></span><span class="op">(</span><span class="fl">0</span>, <span class="fl">0.001</span>, <span class="fl">0.01</span>, <span class="fl">0.1</span>, <span class="fl">1</span>, <span class="fl">10</span><span class="op">)</span><span class="op">)</span></span>
<span></span>
<span><span class="fu"><a href="https://rdrr.io/r/base/cat.html" class="external-link">cat</a></span><span class="op">(</span><span class="st">"Optimal lambda:"</span>, <span class="va">cv_basis</span><span class="op">$</span><span class="va">lambda.opt</span>, <span class="st">"\n"</span><span class="op">)</span></span>
<span><span class="co">#&gt; Optimal lambda:</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/base/cat.html" class="external-link">cat</a></span><span class="op">(</span><span class="st">"CV error by lambda:\n"</span><span class="op">)</span></span>
<span><span class="co">#&gt; CV error by lambda:</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/base/print.html" class="external-link">print</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/Round.html" class="external-link">round</a></span><span class="op">(</span><span class="va">cv_basis</span><span class="op">$</span><span class="va">cv.error</span>, <span class="fl">4</span><span class="op">)</span><span class="op">)</span></span>
<span><span class="co">#&gt;      0  0.001   0.01    0.1      1     10 </span></span>
<span><span class="co">#&gt; 0.5967 0.5926 0.5605 0.4299 0.3209 0.2977</span></span></code></pre></div>
</div>
<div class="section level3">
<h3 id="fourier-basis">Fourier Basis<a class="anchor" aria-label="anchor" href="#fourier-basis"></a>
</h3>
<p>For periodic data, use Fourier basis:</p>
<div class="sourceCode" id="cb9"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">fit_fourier</span> <span class="op">&lt;-</span> <span class="fu"><a href="../reference/fregre.basis.html">fregre.basis</a></span><span class="op">(</span><span class="va">fd</span>, <span class="va">y</span>, nbasis <span class="op">=</span> <span class="fl">11</span>, type <span class="op">=</span> <span class="st">"fourier"</span><span class="op">)</span></span></code></pre></div>
</div>
</div>
<div class="section level2">
<h2 id="nonparametric-regression">Nonparametric Regression<a class="anchor" aria-label="anchor" href="#nonparametric-regression"></a>
</h2>
<p>Nonparametric functional regression makes no parametric assumptions
about the relationship between
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>X</mi><mrow><mo stretchy="true" form="prefix">(</mo><mi>t</mi><mo stretchy="true" form="postfix">)</mo></mrow></mrow><annotation encoding="application/x-tex">X(t)</annotation></semantics></math>
and
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>Y</mi><annotation encoding="application/x-tex">Y</annotation></semantics></math>.
Instead, it estimates
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>ğ”¼</mi><mrow><mo stretchy="true" form="prefix">[</mo><mi>Y</mi><mo stretchy="false" form="prefix">|</mo><mi>X</mi><mo>=</mo><mi>x</mi><mo stretchy="true" form="postfix">]</mo></mrow></mrow><annotation encoding="application/x-tex">\mathbb{E}[Y | X = x]</annotation></semantics></math>
directly using local averaging techniques.</p>
<div class="section level3">
<h3 id="the-general-framework">The General Framework<a class="anchor" aria-label="anchor" href="#the-general-framework"></a>
</h3>
<p>Given a new functional observation
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><msup><mi>X</mi><mo>*</mo></msup><annotation encoding="application/x-tex">X^*</annotation></semantics></math>,
the predicted response is:</p>
<p><math display="block" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msup><mover><mi>Y</mi><mo accent="true">Ì‚</mo></mover><mo>*</mo></msup><mo>=</mo><mover><mi>m</mi><mo accent="true">Ì‚</mo></mover><mrow><mo stretchy="true" form="prefix">(</mo><msup><mi>X</mi><mo>*</mo></msup><mo stretchy="true" form="postfix">)</mo></mrow><mo>=</mo><munderover><mo>âˆ‘</mo><mrow><mi>i</mi><mo>=</mo><mn>1</mn></mrow><mi>n</mi></munderover><msub><mi>w</mi><mi>i</mi></msub><mrow><mo stretchy="true" form="prefix">(</mo><msup><mi>X</mi><mo>*</mo></msup><mo stretchy="true" form="postfix">)</mo></mrow><msub><mi>Y</mi><mi>i</mi></msub></mrow><annotation encoding="application/x-tex">\hat{Y}^* = \hat{m}(X^*) = \sum_{i=1}^{n} w_i(X^*) Y_i</annotation></semantics></math></p>
<p>where
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>w</mi><mi>i</mi></msub><mrow><mo stretchy="true" form="prefix">(</mo><msup><mi>X</mi><mo>*</mo></msup><mo stretchy="true" form="postfix">)</mo></mrow></mrow><annotation encoding="application/x-tex">w_i(X^*)</annotation></semantics></math>
are weights that depend on the â€œdistanceâ€ between
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><msup><mi>X</mi><mo>*</mo></msup><annotation encoding="application/x-tex">X^*</annotation></semantics></math>
and the training curves
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><msub><mi>X</mi><mi>i</mi></msub><annotation encoding="application/x-tex">X_i</annotation></semantics></math>.
Different methods define these weights differently.</p>
</div>
<div class="section level3">
<h3 id="functional-distance">Functional Distance<a class="anchor" aria-label="anchor" href="#functional-distance"></a>
</h3>
<p>A key component is the <strong>semimetric</strong>
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>d</mi><mrow><mo stretchy="true" form="prefix">(</mo><msub><mi>X</mi><mi>i</mi></msub><mo>,</mo><msub><mi>X</mi><mi>j</mi></msub><mo stretchy="true" form="postfix">)</mo></mrow></mrow><annotation encoding="application/x-tex">d(X_i, X_j)</annotation></semantics></math>
measuring similarity between curves. Common choices:</p>
<ul>
<li>
<strong><math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><msup><mi>L</mi><mn>2</mn></msup><annotation encoding="application/x-tex">L^2</annotation></semantics></math>
metric</strong>:
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>d</mi><mrow><mo stretchy="true" form="prefix">(</mo><msub><mi>X</mi><mi>i</mi></msub><mo>,</mo><msub><mi>X</mi><mi>j</mi></msub><mo stretchy="true" form="postfix">)</mo></mrow><mo>=</mo><msqrt><mrow><mo>âˆ«</mo><msup><mrow><mo stretchy="true" form="prefix">[</mo><msub><mi>X</mi><mi>i</mi></msub><mrow><mo stretchy="true" form="prefix">(</mo><mi>t</mi><mo stretchy="true" form="postfix">)</mo></mrow><mo>âˆ’</mo><msub><mi>X</mi><mi>j</mi></msub><mrow><mo stretchy="true" form="prefix">(</mo><mi>t</mi><mo stretchy="true" form="postfix">)</mo></mrow><mo stretchy="true" form="postfix">]</mo></mrow><mn>2</mn></msup><mspace width="0.167em"></mspace><mi>d</mi><mi>t</mi></mrow></msqrt></mrow><annotation encoding="application/x-tex">d(X_i, X_j) = \sqrt{\int [X_i(t) - X_j(t)]^2 \, dt}</annotation></semantics></math>
</li>
<li>
<strong><math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><msup><mi>L</mi><mi>p</mi></msup><annotation encoding="application/x-tex">L^p</annotation></semantics></math>
metric</strong>:
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>d</mi><mrow><mo stretchy="true" form="prefix">(</mo><msub><mi>X</mi><mi>i</mi></msub><mo>,</mo><msub><mi>X</mi><mi>j</mi></msub><mo stretchy="true" form="postfix">)</mo></mrow><mo>=</mo><msup><mrow><mo stretchy="true" form="prefix">(</mo><mo>âˆ«</mo><msup><mrow><mo stretchy="true" form="prefix">|</mo><msub><mi>X</mi><mi>i</mi></msub><mrow><mo stretchy="true" form="prefix">(</mo><mi>t</mi><mo stretchy="true" form="postfix">)</mo></mrow><mo>âˆ’</mo><msub><mi>X</mi><mi>j</mi></msub><mrow><mo stretchy="true" form="prefix">(</mo><mi>t</mi><mo stretchy="true" form="postfix">)</mo></mrow><mo stretchy="true" form="postfix">|</mo></mrow><mi>p</mi></msup><mspace width="0.167em"></mspace><mi>d</mi><mi>t</mi><mo stretchy="true" form="postfix">)</mo></mrow><mrow><mn>1</mn><mi>/</mi><mi>p</mi></mrow></msup></mrow><annotation encoding="application/x-tex">d(X_i, X_j) = \left(\int |X_i(t) - X_j(t)|^p \, dt\right)^{1/p}</annotation></semantics></math>
</li>
<li>
<strong>PCA-based semimetric</strong>:
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>d</mi><mrow><mo stretchy="true" form="prefix">(</mo><msub><mi>X</mi><mi>i</mi></msub><mo>,</mo><msub><mi>X</mi><mi>j</mi></msub><mo stretchy="true" form="postfix">)</mo></mrow><mo>=</mo><msqrt><mrow><msubsup><mo>âˆ‘</mo><mrow><mi>k</mi><mo>=</mo><mn>1</mn></mrow><mi>K</mi></msubsup><msup><mrow><mo stretchy="true" form="prefix">(</mo><msub><mi>Î¾</mi><mrow><mi>i</mi><mi>k</mi></mrow></msub><mo>âˆ’</mo><msub><mi>Î¾</mi><mrow><mi>j</mi><mi>k</mi></mrow></msub><mo stretchy="true" form="postfix">)</mo></mrow><mn>2</mn></msup></mrow></msqrt></mrow><annotation encoding="application/x-tex">d(X_i, X_j) = \sqrt{\sum_{k=1}^{K} (\xi_{ik} - \xi_{jk})^2}</annotation></semantics></math>
using PC scores</li>
</ul>
</div>
<div class="section level3">
<h3 id="nadaraya-watson-estimator">Nadaraya-Watson Estimator<a class="anchor" aria-label="anchor" href="#nadaraya-watson-estimator"></a>
</h3>
<p>The <strong>Nadaraya-Watson</strong> (kernel regression) estimator
uses:</p>
<p><math display="block" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mover><mi>m</mi><mo accent="true">Ì‚</mo></mover><mrow><mo stretchy="true" form="prefix">(</mo><msup><mi>X</mi><mo>*</mo></msup><mo stretchy="true" form="postfix">)</mo></mrow><mo>=</mo><mfrac><mrow><munderover><mo>âˆ‘</mo><mrow><mi>i</mi><mo>=</mo><mn>1</mn></mrow><mi>n</mi></munderover><mi>K</mi><mrow><mo stretchy="true" form="prefix">(</mo><mfrac><mrow><mi>d</mi><mrow><mo stretchy="true" form="prefix">(</mo><msup><mi>X</mi><mo>*</mo></msup><mo>,</mo><msub><mi>X</mi><mi>i</mi></msub><mo stretchy="true" form="postfix">)</mo></mrow></mrow><mi>h</mi></mfrac><mo stretchy="true" form="postfix">)</mo></mrow><msub><mi>Y</mi><mi>i</mi></msub></mrow><mrow><munderover><mo>âˆ‘</mo><mrow><mi>i</mi><mo>=</mo><mn>1</mn></mrow><mi>n</mi></munderover><mi>K</mi><mrow><mo stretchy="true" form="prefix">(</mo><mfrac><mrow><mi>d</mi><mrow><mo stretchy="true" form="prefix">(</mo><msup><mi>X</mi><mo>*</mo></msup><mo>,</mo><msub><mi>X</mi><mi>i</mi></msub><mo stretchy="true" form="postfix">)</mo></mrow></mrow><mi>h</mi></mfrac><mo stretchy="true" form="postfix">)</mo></mrow></mrow></mfrac></mrow><annotation encoding="application/x-tex">\hat{m}(X^*) = \frac{\sum_{i=1}^{n} K\left(\frac{d(X^*, X_i)}{h}\right) Y_i}{\sum_{i=1}^{n} K\left(\frac{d(X^*, X_i)}{h}\right)}</annotation></semantics></math></p>
<p>where
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>K</mi><mrow><mo stretchy="true" form="prefix">(</mo><mo>â‹…</mo><mo stretchy="true" form="postfix">)</mo></mrow></mrow><annotation encoding="application/x-tex">K(\cdot)</annotation></semantics></math>
is a kernel function and
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>h</mi><mo>&gt;</mo><mn>0</mn></mrow><annotation encoding="application/x-tex">h &gt; 0</annotation></semantics></math>
is the <strong>bandwidth</strong> controlling the smoothness:</p>
<ul>
<li>
<strong>Small
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>h</mi><annotation encoding="application/x-tex">h</annotation></semantics></math></strong>:
weights concentrated on nearest neighbors (low bias, high variance)</li>
<li>
<strong>Large
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>h</mi><annotation encoding="application/x-tex">h</annotation></semantics></math></strong>:
weights spread across many observations (high bias, low variance)</li>
</ul>
<p>Common kernels include:</p>
<table class="table">
<thead><tr class="header">
<th>Kernel</th>
<th>Formula
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>K</mi><mrow><mo stretchy="true" form="prefix">(</mo><mi>u</mi><mo stretchy="true" form="postfix">)</mo></mrow></mrow><annotation encoding="application/x-tex">K(u)</annotation></semantics></math>
</th>
</tr></thead>
<tbody>
<tr class="odd">
<td>Gaussian</td>
<td><math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mfrac><mn>1</mn><msqrt><mrow><mn>2</mn><mi>Ï€</mi></mrow></msqrt></mfrac><msup><mi>e</mi><mrow><mo>âˆ’</mo><msup><mi>u</mi><mn>2</mn></msup><mi>/</mi><mn>2</mn></mrow></msup></mrow><annotation encoding="application/x-tex">\frac{1}{\sqrt{2\pi}} e^{-u^2/2}</annotation></semantics></math></td>
</tr>
<tr class="even">
<td>Epanechnikov</td>
<td><math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mfrac><mn>3</mn><mn>4</mn></mfrac><mrow><mo stretchy="true" form="prefix">(</mo><mn>1</mn><mo>âˆ’</mo><msup><mi>u</mi><mn>2</mn></msup><mo stretchy="true" form="postfix">)</mo></mrow><msub><mn>ğŸ</mn><mrow><mrow><mo stretchy="true" form="prefix">|</mo><mi>u</mi><mo stretchy="true" form="postfix">|</mo></mrow><mo>â‰¤</mo><mn>1</mn></mrow></msub></mrow><annotation encoding="application/x-tex">\frac{3}{4}(1-u^2) \mathbf{1}_{|u| \leq 1}</annotation></semantics></math></td>
</tr>
<tr class="odd">
<td>Uniform</td>
<td><math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mfrac><mn>1</mn><mn>2</mn></mfrac><msub><mn>ğŸ</mn><mrow><mrow><mo stretchy="true" form="prefix">|</mo><mi>u</mi><mo stretchy="true" form="postfix">|</mo></mrow><mo>â‰¤</mo><mn>1</mn></mrow></msub></mrow><annotation encoding="application/x-tex">\frac{1}{2} \mathbf{1}_{|u| \leq 1}</annotation></semantics></math></td>
</tr>
</tbody>
</table>
</div>
<div class="section level3">
<h3 id="k-nearest-neighbors">k-Nearest Neighbors<a class="anchor" aria-label="anchor" href="#k-nearest-neighbors"></a>
</h3>
<p>The <strong>k-NN</strong> estimator averages the responses of the
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>k</mi><annotation encoding="application/x-tex">k</annotation></semantics></math>
closest curves:</p>
<p><math display="block" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mover><mi>m</mi><mo accent="true">Ì‚</mo></mover><mrow><mo stretchy="true" form="prefix">(</mo><msup><mi>X</mi><mo>*</mo></msup><mo stretchy="true" form="postfix">)</mo></mrow><mo>=</mo><mfrac><mn>1</mn><mi>k</mi></mfrac><munder><mo>âˆ‘</mo><mrow><mi>i</mi><mo>âˆˆ</mo><msub><mi>ğ’©</mi><mi>k</mi></msub><mrow><mo stretchy="true" form="prefix">(</mo><msup><mi>X</mi><mo>*</mo></msup><mo stretchy="true" form="postfix">)</mo></mrow></mrow></munder><msub><mi>Y</mi><mi>i</mi></msub></mrow><annotation encoding="application/x-tex">\hat{m}(X^*) = \frac{1}{k} \sum_{i \in \mathcal{N}_k(X^*)} Y_i</annotation></semantics></math></p>
<p>where
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>ğ’©</mi><mi>k</mi></msub><mrow><mo stretchy="true" form="prefix">(</mo><msup><mi>X</mi><mo>*</mo></msup><mo stretchy="true" form="postfix">)</mo></mrow></mrow><annotation encoding="application/x-tex">\mathcal{N}_k(X^*)</annotation></semantics></math>
is the set of indices of the
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>k</mi><annotation encoding="application/x-tex">k</annotation></semantics></math>
nearest neighbors of
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><msup><mi>X</mi><mo>*</mo></msup><annotation encoding="application/x-tex">X^*</annotation></semantics></math>.</p>
<p>Two variants are available:</p>
<ul>
<li>
<strong>Global k-NN</strong> (<code>kNN.gCV</code>): single
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>k</mi><annotation encoding="application/x-tex">k</annotation></semantics></math>
selected by leave-one-out cross-validation</li>
<li>
<strong>Local k-NN</strong> (<code>kNN.lCV</code>): adaptive
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>k</mi><annotation encoding="application/x-tex">k</annotation></semantics></math>
that may vary per prediction point</li>
</ul>
</div>
<div class="section level3">
<h3 id="nadaraya-watson-example">Nadaraya-Watson Example<a class="anchor" aria-label="anchor" href="#nadaraya-watson-example"></a>
</h3>
<div class="sourceCode" id="cb10"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="co"># Fit nonparametric regression with Nadaraya-Watson</span></span>
<span><span class="va">fit_np</span> <span class="op">&lt;-</span> <span class="fu"><a href="../reference/fregre.np.html">fregre.np</a></span><span class="op">(</span><span class="va">fd</span>, <span class="va">y</span>, type.S <span class="op">=</span> <span class="st">"S.NW"</span><span class="op">)</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/base/print.html" class="external-link">print</a></span><span class="op">(</span><span class="va">fit_np</span><span class="op">)</span></span>
<span><span class="co">#&gt; Nonparametric functional regression model</span></span>
<span><span class="co">#&gt;   Number of observations: 100 </span></span>
<span><span class="co">#&gt;   Smoother type: S.NW </span></span>
<span><span class="co">#&gt;   Bandwidth: 0.3302789 </span></span>
<span><span class="co">#&gt;   R-squared: 0.0552</span></span></code></pre></div>
</div>
<div class="section level3">
<h3 id="k-nearest-neighbors-1">k-Nearest Neighbors<a class="anchor" aria-label="anchor" href="#k-nearest-neighbors-1"></a>
</h3>
<p>Two flavors of k-NN are available:</p>
<div class="sourceCode" id="cb11"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="co"># Global k-NN (single k for all observations)</span></span>
<span><span class="va">fit_knn_global</span> <span class="op">&lt;-</span> <span class="fu"><a href="../reference/fregre.np.html">fregre.np</a></span><span class="op">(</span><span class="va">fd</span>, <span class="va">y</span>, type.S <span class="op">=</span> <span class="st">"kNN.gCV"</span><span class="op">)</span></span>
<span></span>
<span><span class="co"># Local k-NN (adaptive k per observation)</span></span>
<span><span class="va">fit_knn_local</span> <span class="op">&lt;-</span> <span class="fu"><a href="../reference/fregre.np.html">fregre.np</a></span><span class="op">(</span><span class="va">fd</span>, <span class="va">y</span>, type.S <span class="op">=</span> <span class="st">"kNN.lCV"</span><span class="op">)</span></span>
<span></span>
<span><span class="fu"><a href="https://rdrr.io/r/base/cat.html" class="external-link">cat</a></span><span class="op">(</span><span class="st">"Global k-NN optimal k:"</span>, <span class="va">fit_knn_global</span><span class="op">$</span><span class="va">knn</span>, <span class="st">"\n"</span><span class="op">)</span></span>
<span><span class="co">#&gt; Global k-NN optimal k: 20</span></span></code></pre></div>
</div>
<div class="section level3">
<h3 id="bandwidth-selection">Bandwidth Selection<a class="anchor" aria-label="anchor" href="#bandwidth-selection"></a>
</h3>
<div class="sourceCode" id="cb12"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="co"># Cross-validation for bandwidth</span></span>
<span><span class="va">cv_np</span> <span class="op">&lt;-</span> <span class="fu"><a href="../reference/fregre.np.cv.html">fregre.np.cv</a></span><span class="op">(</span><span class="va">fd</span>, <span class="va">y</span>, h.seq <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/seq.html" class="external-link">seq</a></span><span class="op">(</span><span class="fl">0.1</span>, <span class="fl">1</span>, by <span class="op">=</span> <span class="fl">0.1</span><span class="op">)</span><span class="op">)</span></span>
<span></span>
<span><span class="fu"><a href="https://rdrr.io/r/base/cat.html" class="external-link">cat</a></span><span class="op">(</span><span class="st">"Optimal bandwidth:"</span>, <span class="va">cv_np</span><span class="op">$</span><span class="va">h.opt</span>, <span class="st">"\n"</span><span class="op">)</span></span>
<span><span class="co">#&gt; Optimal bandwidth:</span></span></code></pre></div>
</div>
<div class="section level3">
<h3 id="different-kernels">Different Kernels<a class="anchor" aria-label="anchor" href="#different-kernels"></a>
</h3>
<div class="sourceCode" id="cb13"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="co"># Epanechnikov kernel</span></span>
<span><span class="va">fit_epa</span> <span class="op">&lt;-</span> <span class="fu"><a href="../reference/fregre.np.html">fregre.np</a></span><span class="op">(</span><span class="va">fd</span>, <span class="va">y</span>, Ker <span class="op">=</span> <span class="st">"epa"</span><span class="op">)</span></span>
<span></span>
<span><span class="co"># Available kernels: "norm", "epa", "tri", "quar", "cos", "unif"</span></span></code></pre></div>
</div>
<div class="section level3">
<h3 id="different-metrics">Different Metrics<a class="anchor" aria-label="anchor" href="#different-metrics"></a>
</h3>
<div class="sourceCode" id="cb14"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="co"># Use L1 metric instead of default L2</span></span>
<span><span class="va">fit_np_l1</span> <span class="op">&lt;-</span> <span class="fu"><a href="../reference/fregre.np.html">fregre.np</a></span><span class="op">(</span><span class="va">fd</span>, <span class="va">y</span>, metric <span class="op">=</span> <span class="va">metric.lp</span>, p <span class="op">=</span> <span class="fl">1</span><span class="op">)</span></span>
<span></span>
<span><span class="co"># Use semimetric based on PCA</span></span>
<span><span class="va">fit_np_pca</span> <span class="op">&lt;-</span> <span class="fu"><a href="../reference/fregre.np.html">fregre.np</a></span><span class="op">(</span><span class="va">fd</span>, <span class="va">y</span>, metric <span class="op">=</span> <span class="va">semimetric.pca</span>, ncomp <span class="op">=</span> <span class="fl">5</span><span class="op">)</span></span></code></pre></div>
</div>
</div>
<div class="section level2">
<h2 id="comparing-methods">Comparing Methods<a class="anchor" aria-label="anchor" href="#comparing-methods"></a>
</h2>
<div class="sourceCode" id="cb15"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="co"># Fit all methods on training data</span></span>
<span><span class="va">fit1</span> <span class="op">&lt;-</span> <span class="fu"><a href="../reference/fregre.pc.html">fregre.pc</a></span><span class="op">(</span><span class="va">fd_train</span>, <span class="va">y_train</span>, ncomp <span class="op">=</span> <span class="fl">3</span><span class="op">)</span></span>
<span><span class="va">fit2</span> <span class="op">&lt;-</span> <span class="fu"><a href="../reference/fregre.basis.html">fregre.basis</a></span><span class="op">(</span><span class="va">fd_train</span>, <span class="va">y_train</span>, nbasis <span class="op">=</span> <span class="fl">15</span><span class="op">)</span></span>
<span><span class="va">fit3</span> <span class="op">&lt;-</span> <span class="fu"><a href="../reference/fregre.np.html">fregre.np</a></span><span class="op">(</span><span class="va">fd_train</span>, <span class="va">y_train</span>, type.S <span class="op">=</span> <span class="st">"kNN.gCV"</span><span class="op">)</span></span>
<span></span>
<span><span class="co"># Predict on test data</span></span>
<span><span class="va">pred1</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/stats/predict.html" class="external-link">predict</a></span><span class="op">(</span><span class="va">fit1</span>, <span class="va">fd_test</span><span class="op">)</span></span>
<span><span class="va">pred2</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/stats/predict.html" class="external-link">predict</a></span><span class="op">(</span><span class="va">fit2</span>, <span class="va">fd_test</span><span class="op">)</span></span>
<span><span class="va">pred3</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/stats/predict.html" class="external-link">predict</a></span><span class="op">(</span><span class="va">fit3</span>, <span class="va">fd_test</span><span class="op">)</span></span>
<span></span>
<span><span class="co"># Compare performance</span></span>
<span><span class="va">results</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/data.frame.html" class="external-link">data.frame</a></span><span class="op">(</span></span>
<span>  Method <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html" class="external-link">c</a></span><span class="op">(</span><span class="st">"PC Regression"</span>, <span class="st">"Basis Regression"</span>, <span class="st">"k-NN"</span><span class="op">)</span>,</span>
<span>  RMSE <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html" class="external-link">c</a></span><span class="op">(</span><span class="fu"><a href="../reference/pred.RMSE.html">pred.RMSE</a></span><span class="op">(</span><span class="va">y_test</span>, <span class="va">pred1</span><span class="op">)</span>,</span>
<span>           <span class="fu"><a href="../reference/pred.RMSE.html">pred.RMSE</a></span><span class="op">(</span><span class="va">y_test</span>, <span class="va">pred2</span><span class="op">)</span>,</span>
<span>           <span class="fu"><a href="../reference/pred.RMSE.html">pred.RMSE</a></span><span class="op">(</span><span class="va">y_test</span>, <span class="va">pred3</span><span class="op">)</span><span class="op">)</span>,</span>
<span>  R2 <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html" class="external-link">c</a></span><span class="op">(</span><span class="fu"><a href="../reference/pred.R2.html">pred.R2</a></span><span class="op">(</span><span class="va">y_test</span>, <span class="va">pred1</span><span class="op">)</span>,</span>
<span>         <span class="fu"><a href="../reference/pred.R2.html">pred.R2</a></span><span class="op">(</span><span class="va">y_test</span>, <span class="va">pred2</span><span class="op">)</span>,</span>
<span>         <span class="fu"><a href="../reference/pred.R2.html">pred.R2</a></span><span class="op">(</span><span class="va">y_test</span>, <span class="va">pred3</span><span class="op">)</span><span class="op">)</span></span>
<span><span class="op">)</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/base/print.html" class="external-link">print</a></span><span class="op">(</span><span class="va">results</span><span class="op">)</span></span>
<span><span class="co">#&gt;             Method      RMSE          R2</span></span>
<span><span class="co">#&gt; 1    PC Regression 0.4570245  0.21884391</span></span>
<span><span class="co">#&gt; 2 Basis Regression 0.8989962 -2.02255778</span></span>
<span><span class="co">#&gt; 3             k-NN 0.4935318  0.08906132</span></span></code></pre></div>
</div>
<div class="section level2">
<h2 id="visualizing-predictions">Visualizing Predictions<a class="anchor" aria-label="anchor" href="#visualizing-predictions"></a>
</h2>
<div class="sourceCode" id="cb16"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="co"># Create comparison data frame</span></span>
<span><span class="va">df_pred</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/data.frame.html" class="external-link">data.frame</a></span><span class="op">(</span></span>
<span>  Observed <span class="op">=</span> <span class="va">y_test</span>,</span>
<span>  PC <span class="op">=</span> <span class="va">pred1</span>,</span>
<span>  Basis <span class="op">=</span> <span class="va">pred2</span>,</span>
<span>  kNN <span class="op">=</span> <span class="va">pred3</span></span>
<span><span class="op">)</span></span>
<span></span>
<span><span class="co"># Observed vs predicted</span></span>
<span><span class="fu"><a href="https://ggplot2.tidyverse.org/reference/ggplot.html" class="external-link">ggplot</a></span><span class="op">(</span><span class="va">df_pred</span>, <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/aes.html" class="external-link">aes</a></span><span class="op">(</span>x <span class="op">=</span> <span class="va">Observed</span>, y <span class="op">=</span> <span class="va">PC</span><span class="op">)</span><span class="op">)</span> <span class="op">+</span></span>
<span>  <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/geom_point.html" class="external-link">geom_point</a></span><span class="op">(</span><span class="op">)</span> <span class="op">+</span></span>
<span>  <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/geom_abline.html" class="external-link">geom_abline</a></span><span class="op">(</span>intercept <span class="op">=</span> <span class="fl">0</span>, slope <span class="op">=</span> <span class="fl">1</span>, linetype <span class="op">=</span> <span class="st">"dashed"</span>, color <span class="op">=</span> <span class="st">"red"</span><span class="op">)</span> <span class="op">+</span></span>
<span>  <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/labs.html" class="external-link">labs</a></span><span class="op">(</span>title <span class="op">=</span> <span class="st">"PC Regression: Observed vs Predicted"</span>,</span>
<span>       x <span class="op">=</span> <span class="st">"Observed"</span>, y <span class="op">=</span> <span class="st">"Predicted"</span><span class="op">)</span> <span class="op">+</span></span>
<span>  <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/ggtheme.html" class="external-link">theme_minimal</a></span><span class="op">(</span><span class="op">)</span></span></code></pre></div>
<p><img src="regression_files/figure-html/vis-predictions-1.png" class="r-plt" alt="" width="100%"></p>
</div>
<div class="section level2">
<h2 id="method-selection-guide">Method Selection Guide<a class="anchor" aria-label="anchor" href="#method-selection-guide"></a>
</h2>
<div class="section level3">
<h3 id="when-to-use-each-method">When to Use Each Method<a class="anchor" aria-label="anchor" href="#when-to-use-each-method"></a>
</h3>
<p><strong>Principal Component Regression</strong>
(<code>fregre.pc</code>):</p>
<ul>
<li>Best when the functional predictor has clear dominant modes of
variation</li>
<li>Computationally efficient for large datasets</li>
<li>Interpretable: each PC represents a pattern in the data</li>
<li>Use when
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>n</mi><annotation encoding="application/x-tex">n</annotation></semantics></math>
is small relative to the complexity of
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>X</mi><mrow><mo stretchy="true" form="prefix">(</mo><mi>t</mi><mo stretchy="true" form="postfix">)</mo></mrow></mrow><annotation encoding="application/x-tex">X(t)</annotation></semantics></math>
</li>
</ul>
<p><strong>Basis Expansion Regression</strong>
(<code>fregre.basis</code>):</p>
<ul>
<li>Best when you believe
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>Î²</mi><mrow><mo stretchy="true" form="prefix">(</mo><mi>t</mi><mo stretchy="true" form="postfix">)</mo></mrow></mrow><annotation encoding="application/x-tex">\beta(t)</annotation></semantics></math>
is smooth</li>
<li>Use B-splines for local features, Fourier for periodic patterns</li>
<li>The penalty parameter
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>Î»</mi><annotation encoding="application/x-tex">\lambda</annotation></semantics></math>
provides automatic regularization</li>
<li>Good when you want to visualize and interpret
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mover><mi>Î²</mi><mo accent="true">Ì‚</mo></mover><mrow><mo stretchy="true" form="prefix">(</mo><mi>t</mi><mo stretchy="true" form="postfix">)</mo></mrow></mrow><annotation encoding="application/x-tex">\hat{\beta}(t)</annotation></semantics></math>
</li>
</ul>
<p><strong>Nonparametric Regression</strong>
(<code>fregre.np</code>):</p>
<ul>
<li>Best when the relationship between
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>X</mi><annotation encoding="application/x-tex">X</annotation></semantics></math>
and
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>Y</mi><annotation encoding="application/x-tex">Y</annotation></semantics></math>
may be nonlinear</li>
<li>Makes minimal assumptions about the data-generating process</li>
<li>Computationally more expensive (requires distance calculations)</li>
<li>May require larger sample sizes for stable estimation</li>
</ul>
</div>
<div class="section level3">
<h3 id="comparison-table">Comparison Table<a class="anchor" aria-label="anchor" href="#comparison-table"></a>
</h3>
<table class="table">
<colgroup>
<col width="13%">
<col width="11%">
<col width="24%">
<col width="21%">
<col width="29%">
</colgroup>
<thead><tr class="header">
<th>Method</th>
<th>Model</th>
<th>Key Parameter</th>
<th>Computation</th>
<th>Interpretability</th>
</tr></thead>
<tbody>
<tr class="odd">
<td>PC Regression</td>
<td><math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>Y</mi><mo>=</mo><mi>Î±</mi><mo>+</mo><msub><mo>âˆ‘</mo><mi>k</mi></msub><msub><mi>Î³</mi><mi>k</mi></msub><msub><mi>Î¾</mi><mrow><mi>i</mi><mi>k</mi></mrow></msub></mrow><annotation encoding="application/x-tex">Y = \alpha + \sum_k \gamma_k \xi_{ik}</annotation></semantics></math></td>
<td>
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>K</mi><annotation encoding="application/x-tex">K</annotation></semantics></math>
(# components)</td>
<td>Fast</td>
<td>High</td>
</tr>
<tr class="even">
<td>Basis Regression</td>
<td><math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>Y</mi><mo>=</mo><mi>Î±</mi><mo>+</mo><mo>âˆ«</mo><mi>Î²</mi><mrow><mo stretchy="true" form="prefix">(</mo><mi>t</mi><mo stretchy="true" form="postfix">)</mo></mrow><mi>X</mi><mrow><mo stretchy="true" form="prefix">(</mo><mi>t</mi><mo stretchy="true" form="postfix">)</mo></mrow><mi>d</mi><mi>t</mi></mrow><annotation encoding="application/x-tex">Y = \alpha + \int \beta(t) X(t) dt</annotation></semantics></math></td>
<td>
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>Î»</mi><annotation encoding="application/x-tex">\lambda</annotation></semantics></math>
(penalty)</td>
<td>Fast</td>
<td>High</td>
</tr>
<tr class="odd">
<td>Nadaraya-Watson</td>
<td>
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>Y</mi><mo>=</mo><mi>m</mi><mrow><mo stretchy="true" form="prefix">(</mo><mi>X</mi><mo stretchy="true" form="postfix">)</mo></mrow></mrow><annotation encoding="application/x-tex">Y = m(X)</annotation></semantics></math>
(nonparametric)</td>
<td>
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>h</mi><annotation encoding="application/x-tex">h</annotation></semantics></math>
(bandwidth)</td>
<td>Moderate</td>
<td>Low</td>
</tr>
<tr class="even">
<td>k-NN</td>
<td><math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>Y</mi><mo>=</mo><mfrac><mn>1</mn><mi>k</mi></mfrac><msub><mo>âˆ‘</mo><mrow><mi>j</mi><mo>âˆˆ</mo><msub><mi>ğ’©</mi><mi>k</mi></msub></mrow></msub><msub><mi>Y</mi><mi>j</mi></msub></mrow><annotation encoding="application/x-tex">Y = \frac{1}{k}\sum_{j \in \mathcal{N}_k} Y_j</annotation></semantics></math></td>
<td>
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>k</mi><annotation encoding="application/x-tex">k</annotation></semantics></math>
(neighbors)</td>
<td>Moderate</td>
<td>Low</td>
</tr>
</tbody>
</table>
</div>
</div>
<div class="section level2">
<h2 id="prediction-metrics">Prediction Metrics<a class="anchor" aria-label="anchor" href="#prediction-metrics"></a>
</h2>
<p>Model performance is evaluated using standard regression metrics.
Given observed values
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>y</mi><mn>1</mn></msub><mo>,</mo><mi>â€¦</mi><mo>,</mo><msub><mi>y</mi><mi>n</mi></msub></mrow><annotation encoding="application/x-tex">y_1, \ldots, y_n</annotation></semantics></math>
and predictions
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mover><mi>y</mi><mo accent="true">Ì‚</mo></mover><mn>1</mn></msub><mo>,</mo><mi>â€¦</mi><mo>,</mo><msub><mover><mi>y</mi><mo accent="true">Ì‚</mo></mover><mi>n</mi></msub></mrow><annotation encoding="application/x-tex">\hat{y}_1, \ldots, \hat{y}_n</annotation></semantics></math>:</p>
<table class="table">
<colgroup>
<col width="24%">
<col width="27%">
<col width="48%">
</colgroup>
<thead><tr class="header">
<th>Metric</th>
<th>Formula</th>
<th>Interpretation</th>
</tr></thead>
<tbody>
<tr class="odd">
<td>MAE</td>
<td><math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mfrac><mn>1</mn><mi>n</mi></mfrac><msubsup><mo>âˆ‘</mo><mrow><mi>i</mi><mo>=</mo><mn>1</mn></mrow><mi>n</mi></msubsup><mrow><mo stretchy="true" form="prefix">|</mo><msub><mi>y</mi><mi>i</mi></msub><mo>âˆ’</mo><msub><mover><mi>y</mi><mo accent="true">Ì‚</mo></mover><mi>i</mi></msub><mo stretchy="true" form="postfix">|</mo></mrow></mrow><annotation encoding="application/x-tex">\frac{1}{n}\sum_{i=1}^n |y_i - \hat{y}_i|</annotation></semantics></math></td>
<td>Average absolute error</td>
</tr>
<tr class="even">
<td>MSE</td>
<td><math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mfrac><mn>1</mn><mi>n</mi></mfrac><msubsup><mo>âˆ‘</mo><mrow><mi>i</mi><mo>=</mo><mn>1</mn></mrow><mi>n</mi></msubsup><msup><mrow><mo stretchy="true" form="prefix">(</mo><msub><mi>y</mi><mi>i</mi></msub><mo>âˆ’</mo><msub><mover><mi>y</mi><mo accent="true">Ì‚</mo></mover><mi>i</mi></msub><mo stretchy="true" form="postfix">)</mo></mrow><mn>2</mn></msup></mrow><annotation encoding="application/x-tex">\frac{1}{n}\sum_{i=1}^n (y_i - \hat{y}_i)^2</annotation></semantics></math></td>
<td>Average squared error</td>
</tr>
<tr class="odd">
<td>RMSE</td>
<td><math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><msqrt><mtext mathvariant="normal">MSE</mtext></msqrt><annotation encoding="application/x-tex">\sqrt{\text{MSE}}</annotation></semantics></math></td>
<td>Error in original units</td>
</tr>
<tr class="even">
<td><math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><msup><mi>R</mi><mn>2</mn></msup><annotation encoding="application/x-tex">R^2</annotation></semantics></math></td>
<td><math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>1</mn><mo>âˆ’</mo><mfrac><mrow><mo>âˆ‘</mo><msup><mrow><mo stretchy="true" form="prefix">(</mo><msub><mi>y</mi><mi>i</mi></msub><mo>âˆ’</mo><msub><mover><mi>y</mi><mo accent="true">Ì‚</mo></mover><mi>i</mi></msub><mo stretchy="true" form="postfix">)</mo></mrow><mn>2</mn></msup></mrow><mrow><mo>âˆ‘</mo><msup><mrow><mo stretchy="true" form="prefix">(</mo><msub><mi>y</mi><mi>i</mi></msub><mo>âˆ’</mo><mover><mi>y</mi><mo accent="true">â€¾</mo></mover><mo stretchy="true" form="postfix">)</mo></mrow><mn>2</mn></msup></mrow></mfrac></mrow><annotation encoding="application/x-tex">1 - \frac{\sum(y_i - \hat{y}_i)^2}{\sum(y_i - \bar{y})^2}</annotation></semantics></math></td>
<td>Proportion of variance explained</td>
</tr>
</tbody>
</table>
<div class="sourceCode" id="cb17"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="co"># Available metrics for model evaluation</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/base/cat.html" class="external-link">cat</a></span><span class="op">(</span><span class="st">"MAE:"</span>, <span class="fu"><a href="../reference/pred.MAE.html">pred.MAE</a></span><span class="op">(</span><span class="va">y_test</span>, <span class="va">pred1</span><span class="op">)</span>, <span class="st">"\n"</span><span class="op">)</span></span>
<span><span class="co">#&gt; MAE: 0.3819577</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/base/cat.html" class="external-link">cat</a></span><span class="op">(</span><span class="st">"MSE:"</span>, <span class="fu"><a href="../reference/pred.MSE.html">pred.MSE</a></span><span class="op">(</span><span class="va">y_test</span>, <span class="va">pred1</span><span class="op">)</span>, <span class="st">"\n"</span><span class="op">)</span></span>
<span><span class="co">#&gt; MSE: 0.2088714</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/base/cat.html" class="external-link">cat</a></span><span class="op">(</span><span class="st">"RMSE:"</span>, <span class="fu"><a href="../reference/pred.RMSE.html">pred.RMSE</a></span><span class="op">(</span><span class="va">y_test</span>, <span class="va">pred1</span><span class="op">)</span>, <span class="st">"\n"</span><span class="op">)</span></span>
<span><span class="co">#&gt; RMSE: 0.4570245</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/base/cat.html" class="external-link">cat</a></span><span class="op">(</span><span class="st">"R2:"</span>, <span class="fu"><a href="../reference/pred.R2.html">pred.R2</a></span><span class="op">(</span><span class="va">y_test</span>, <span class="va">pred1</span><span class="op">)</span>, <span class="st">"\n"</span><span class="op">)</span></span>
<span><span class="co">#&gt; R2: 0.2188439</span></span></code></pre></div>
<div class="section level3">
<h3 id="cross-validation">Cross-Validation<a class="anchor" aria-label="anchor" href="#cross-validation"></a>
</h3>
<p>All methods support <strong>leave-one-out cross-validation</strong>
(LOOCV) for parameter selection:</p>
<p><math display="block" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mtext mathvariant="normal">CV</mtext><mo>=</mo><mfrac><mn>1</mn><mi>n</mi></mfrac><munderover><mo>âˆ‘</mo><mrow><mi>i</mi><mo>=</mo><mn>1</mn></mrow><mi>n</mi></munderover><msup><mrow><mo stretchy="true" form="prefix">(</mo><msub><mi>Y</mi><mi>i</mi></msub><mo>âˆ’</mo><msub><mover><mi>Y</mi><mo accent="true">Ì‚</mo></mover><mrow><mo>âˆ’</mo><mi>i</mi></mrow></msub><mo stretchy="true" form="postfix">)</mo></mrow><mn>2</mn></msup></mrow><annotation encoding="application/x-tex">\text{CV} = \frac{1}{n} \sum_{i=1}^{n} (Y_i - \hat{Y}_{-i})^2</annotation></semantics></math></p>
<p>where
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><msub><mover><mi>Y</mi><mo accent="true">Ì‚</mo></mover><mrow><mo>âˆ’</mo><mi>i</mi></mrow></msub><annotation encoding="application/x-tex">\hat{Y}_{-i}</annotation></semantics></math>
is the prediction for observation
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>i</mi><annotation encoding="application/x-tex">i</annotation></semantics></math>
when it is left out of the training set. This is implemented efficiently
using the â€œhat matrix trickâ€ for linear methods.</p>
</div>
</div>
<div class="section level2">
<h2 id="references">References<a class="anchor" aria-label="anchor" href="#references"></a>
</h2>
<p><strong>Foundational texts:</strong></p>
<ul>
<li>Ramsay, J.O. and Silverman, B.W. (2005). <em>Functional Data
Analysis</em>, 2nd ed.Â Springer.</li>
<li>Ferraty, F. and Vieu, P. (2006). <em>Nonparametric Functional Data
Analysis: Theory and Practice</em>. Springer.</li>
<li>HorvÃ¡th, L. and Kokoszka, P. (2012). <em>Inference for Functional
Data with Applications</em>. Springer.</li>
</ul>
<p><strong>Key methodological papers:</strong></p>
<ul>
<li>Cardot, H., Ferraty, F., and Sarda, P. (1999). Functional Linear
Model. <em>Statistics &amp; Probability Letters</em>, 45(1), 11-22.</li>
<li>Reiss, P.T. and Ogden, R.T. (2007). Functional Principal Component
Regression and Functional Partial Least Squares. <em>Journal of the
American Statistical Association</em>, 102(479), 984-996.</li>
<li>Goldsmith, J., Bobb, J., Crainiceanu, C., Caffo, B., and Reich, D.
(2011). Penalized Functional Regression. <em>Journal of Computational
and Graphical Statistics</em>, 20(4), 830-851.</li>
</ul>
<p><strong>On nonparametric functional regression:</strong></p>
<ul>
<li>Ferraty, F., Laksaci, A., and Vieu, P. (2006). Estimating Some
Characteristics of the Conditional Distribution in Nonparametric
Functional Models. <em>Statistical Inference for Stochastic
Processes</em>, 9, 47-76.</li>
</ul>
</div>
  </main><aside class="col-md-3"><nav id="toc" aria-label="Table of contents"><h2>On this page</h2>
    </nav></aside>
</div>



    <footer><div class="pkgdown-footer-left">
  <p>Developed by Simon MÃ¼ller.</p>
</div>

<div class="pkgdown-footer-right">
  <p>Site built with <a href="https://pkgdown.r-lib.org/" class="external-link">pkgdown</a> 2.2.0.</p>
</div>

    </footer>
</div>





  </body>
</html>
